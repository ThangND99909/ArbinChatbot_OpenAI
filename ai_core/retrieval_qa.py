# ai_core/retrieval_qa.py
from langchain.prompts import PromptTemplate
from typing import Dict, Any, List, Optional, Tuple
from .nlu_processor import NLUProcessor
from .memory_manager import ArbinMemoryManager
from ai_core.utils.text_normalizer import remove_accents

import traceback
import re

class ArbinRetrievalQA:
    """
    Lá»›p chÃ­nh cho mÃ´-Ä‘un Há»i-ÄÃ¡p (QA) trong chatbot Arbin Instruments.
    """
    def __init__(self, llm, vector_store):
        self.llm = llm
        self.vector_store = vector_store
        
        # Bá»™ nhá»› há»™i thoáº¡i
        self.memory_manager = ArbinMemoryManager()
        
        # NLU Processor vá»›i memory integration
        self.nlu_processor = NLUProcessor(llm, memory_manager=self.memory_manager)
        
        # Thiáº¿t láº­p cÃ¡c Prompt Template
        self.setup_qa_chains()
        self._setup_language_detection()

    def _setup_language_detection(self):
        """Cáº¥u hÃ¬nh language detection patterns"""
        self.VIETNAMESE_CHARS = "Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘"
        self.VIETNAMESE_WORDS = [
            "cá»§a", "lÃ ", "vÃ ", "cÃ³", "Ä‘Æ°á»£c", "trong", "cho", "vá»›i", 
            "táº¡i", "tá»«", "nhÆ°", "vá»", "nÃ y", "khi", "cÃ¡c"
        ]
        self.VIETNAMESE_PHRASES = [
            "lÃ  gÃ¬", "bao nhiÃªu", "tháº¿ nÃ o", "táº¡i sao", 
            "á»Ÿ Ä‘Ã¢u", "cÃ³ thá»ƒ", "lÃ m sao"
        ]
        self.ENGLISH_PATTERNS = [
            "what", "how", "why", "when", "where", 
            "which", "can you", "could you", "please"
        ]
        self.COMMON_ENGLISH = ["hello", "hi", "hey", "greetings"]

        self.GREETING_PATTERNS = [
            # English
            "hello", "hi", "hey", "greetings",
            # Vietnamese
            "xin chÃ o", "chÃ o", "chÃ o báº¡n", "chÃ o bot",
            # Short forms
            "helo", "hii", "heyy"
        ]

    def detect_language(self, text: str) -> str:
        return self._detect_language(text)

    def _detect_language(self, text: str) -> str:
        if not text or not isinstance(text, str):
            return "en"
        text_lower = text.lower().strip()

        # RULE 1: Vietnamese characters
        if any(char in text for char in self.VIETNAMESE_CHARS):
            return "vi"

        # RULE 2: Vietnamese phrases
        if any(phrase in text_lower for phrase in self.VIETNAMESE_PHRASES):
            return "vi"

        # RULE 3: Multiple Vietnamese words
        vi_words_found = [word for word in self.VIETNAMESE_WORDS if word in text_lower]
        if len(vi_words_found) >= 2:
            return "vi"

        # RULE 4: English patterns
        if any(pattern in text_lower for pattern in self.ENGLISH_PATTERNS):
            return "en"

        # RULE 5: Common English words - exact match
        words = text_lower.split()
        if any(word in self.COMMON_ENGLISH for word in words):
            return "en"

        # RULE 6: Short technical query
        if len(words) <= 3:
            technical_terms = ["bt-", "mits", "arbin", "voltage", "current", "battery"]
            if any(term in text_lower for term in technical_terms):
                return "en"

        # Default
        return "en"

    def _is_greeting(self, text: str) -> bool:
        """Cáº£i tiáº¿n: kiá»ƒm tra greeting khÃ´ng dÃ¹ng substring trong tá»«"""
        if not text or not isinstance(text, str):
            return False
        text_lower = text.lower().strip()
        text_clean = re.sub(r'[^\w\s]', '', text_lower)

        # Exact match
        if text_clean in self.GREETING_PATTERNS:
            return True

        # Optional: check first word exact match only
        first_word = text_clean.split()[0] if text_clean.split() else ""
        if first_word in self.GREETING_PATTERNS:
            return True

        return False
    
    
    def _resolve_language(self, question: str, user_language: str = None) -> str:
        """
        XÃ¡c Ä‘á»‹nh ngÃ´n ngá»¯ cuá»‘i cÃ¹ng Ä‘á»ƒ dÃ¹ng
        Priority: user_provided > auto_detected > default
        """
        # Priority 1: User explicitly provided
        if user_language and user_language in ["vi", "en"]:
            print(f"âœ“ Using user-provided language: {user_language}")
            return user_language
        
        # Priority 2: Auto-detect
        detected = self._detect_language(question)
        print(f"âœ“ Auto-detected language: {detected} for: '{question[:50]}...'")
        
        return detected
    
    

    # ========================== Táº O PROMPT CHO Tá»ªNG INTENT ==========================
    def setup_qa_chains(self):
        """Thiáº¿t láº­p cÃ¡c QA chain dÃ¹ng prompt tá»« prompts.py"""

        from ai_core.prompts import (
            greeting_prompt,
            qa_prompt,
            tech_support_prompt,
            comparison_prompt,
            general_support_prompt,
            greeting_prompt
        )

        # Mapping intent â†’ prompt template
        self.prompt_mapping = {
            "greeting": greeting_prompt,
            "product_inquiry": qa_prompt,
            "technical_support": tech_support_prompt,
            "specification_request": qa_prompt,
            "comparison_request": comparison_prompt,
            "application_info": qa_prompt,
            "pricing_inquiry": general_support_prompt,
            "general_info": general_support_prompt,
            "troubleshooting": tech_support_prompt,
            "other": general_support_prompt
        }

        print("âœ… QA prompt chains loaded from ai_core/prompts.py")


    def _generate_response(self, question: str, context: str, intent: str,
                       language: str, chat_history: str, entities: Dict) -> str:
        """Generate response (OpenAI-compatible, dÃ¹ng prompts.py)"""

        # 1ï¸âƒ£ Chá»n ChatPromptTemplate tá»« mapping
        selected_prompt = self.prompt_mapping.get(intent, self.prompt_mapping["other"])

        try:
            # 2ï¸âƒ£ Format text prompt (OpenAI chá»‰ nháº­n chuá»—i)
            prompt_text = selected_prompt.format(
                context=context,
                question=question,
                language=language
            )

            # 3ï¸âƒ£ System message cá»©ng (báº¯t buá»™c tuÃ¢n thá»§ ngÃ´n ngá»¯)
            system_message = {
                "vi": (
                "Báº¡n lÃ  trá»£ lÃ½ ká»¹ thuáº­t áº£o cá»§a Arbin Instruments â€” cÃ´ng ty hÃ ng Ä‘áº§u vá» thiáº¿t bá»‹ thá»­ nghiá»‡m pin.\n\n"
                "Má»¤C TIÃŠU:\n"
                "- Há»— trá»£ khÃ¡ch hÃ ng Viá»‡t Nam trong viá»‡c tÃ¬m hiá»ƒu sáº£n pháº©m, thÃ´ng sá»‘ ká»¹ thuáº­t, hÆ°á»›ng dáº«n sá»­ dá»¥ng vÃ  kháº¯c phá»¥c sá»± cá»‘ cá»§a Arbin.\n"
                "- Giáº£i thÃ­ch ngáº¯n gá»n, rÃµ rÃ ng, cÃ³ dáº¥u Ä‘áº§y Ä‘á»§.\n"
                "- Náº¿u khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin, hÃ£y nÃ³i rÃµ Ä‘iá»u Ä‘Ã³ vÃ  gá»£i Ã½ nÆ¡i ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ xem thÃªm (vÃ­ dá»¥: www.arbin.com hoáº·c email support@arbin.com).\n\n"
                "YÃŠU Cáº¦U NGÃ”N NGá»®:\n"
                "- Tráº£ lá»i 100% báº±ng TIáº¾NG VIá»†T cÃ³ dáº¥u.\n"
                "- KhÃ´ng sá»­ dá»¥ng tiáº¿ng Anh.\n"
                "- Giá»¯ giá»ng Ä‘iá»‡u chuyÃªn nghiá»‡p, rÃµ rÃ ng, táº­p trung vÃ o ná»™i dung ká»¹ thuáº­t.\n"
                "- KhÃ´ng cáº§n chÃ o há»i hoáº·c cáº£m Æ¡n trong pháº§n tráº£ lá»i.\n\n"
            ),
            "en": (
                "You are Arbin Instruments' virtual technical assistant â€” a global leader in battery testing systems.\n\n"
                "GOAL:\n"
                "- Help users understand Arbin products, specifications, setup guides, and troubleshooting steps.\n"
                "- Provide clear, accurate, and concise explanations.\n"
                "- If documentation is incomplete, state that honestly and suggest where to find more (e.g., www.arbin.com or support@arbin.com).\n\n"
                "LANGUAGE REQUIREMENTS:\n"
                "- Respond 100% in ENGLISH.\n"
                "- Do NOT use Vietnamese.\n"
                "- Maintain a professional and concise tone."
                "- Avoid greetings or thank-you phrases at the beginning of responses.\n\n"
            )
            }.get(language, "You are Arbin assistant.\n\n")

            # 4ï¸âƒ£ Gá»™p system + chat_history + prompt thÃ nh messages format cho OpenAI
            messages = [
                {"role": "system", "content": system_message}
            ]
            
            # ThÃªm chat history náº¿u cÃ³
            if chat_history:
                # Parse chat history thÃ nh cÃ¡c message
                history_messages = self._parse_chat_history_for_openai(chat_history)
                messages.extend(history_messages)
            
            # ThÃªm user question
            messages.append({"role": "user", "content": prompt_text})
            
            print("ðŸ§  [OpenAI Prompt Preview]:")
            for msg in messages:
                print(f"[{msg['role']}]: {msg['content'][:300]}...")
            
            # 5ï¸âƒ£ Gá»i OpenAI API
            try:
                # Gá»i invoke method cá»§a OpenAILLM vá»›i messages format
                response = self.llm.invoke(messages)
                if isinstance(response, dict):
                    response = response.get('text', '')
                elif hasattr(response, 'content'):
                    response = response.content
                intent_result = self.intent_llm.invoke({"question": question, "language": language})
                intent = intent_result.get("intent", "unknown")
                if intent == "out_of_domain":
                    return "Xin lá»—i, tÃ´i chá»‰ tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n Arbin Instruments vÃ  thiáº¿t bá»‹ thá»­ nghiá»‡m pin."
                    
            except Exception as e:
                print(f"OpenAI API error: {e}, trying alternative method...")
                # Fallback: gá»­i plain text
                full_prompt = f"{system_message}\n\nPrevious chat history:\n{chat_history}\n\n{prompt_text}"
                response = self.llm.invoke(full_prompt)
                if hasattr(response, 'text'):
                    response = response.text

            # 6ï¸âƒ£ Chuáº©n hoÃ¡ output
            response = self._validate_response_language(response, language)
            return response.strip()

        except Exception as e:
            print(f"âŒ Lá»—i generate_response (OpenAI): {e}")
            import traceback; traceback.print_exc()
            return (
                "Xin lá»—i, tÃ´i gáº·p sá»± cá»‘ khi táº¡o cÃ¢u tráº£ lá»i. "
                "Vui lÃ²ng thá»­ láº¡i hoáº·c liÃªn há»‡ support@arbin.com."
            )

    def _parse_chat_history_for_openai(self, chat_history: str) -> List[Dict[str, str]]:
        """Parse chat history text thÃ nh format messages cho OpenAI"""
        messages = []
        if not chat_history:
            return messages
            
        # Giáº£ sá»­ chat_history cÃ³ format: "User: ...\nAssistant: ..."
        lines = chat_history.split('\n')
        current_role = None
        current_content = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # XÃ¡c Ä‘á»‹nh role
            if line.lower().startswith('user:'):
                if current_role and current_content:
                    messages.append({"role": current_role.lower(), "content": ' '.join(current_content)})
                current_role = 'user'
                current_content = [line[5:].strip()]  # Bá» 'User:'
            elif line.lower().startswith('assistant:'):
                if current_role and current_content:
                    messages.append({"role": current_role.lower(), "content": ' '.join(current_content)})
                current_role = 'assistant'
                current_content = [line[10:].strip()]  # Bá» 'Assistant:'
            else:
                # Tiáº¿p tá»¥c content cá»§a message hiá»‡n táº¡i
                if current_role:
                    current_content.append(line)
        
        # ThÃªm message cuá»‘i cÃ¹ng
        if current_role and current_content:
            messages.append({"role": current_role.lower(), "content": ' '.join(current_content)})
        
        # Giá»›i háº¡n sá»‘ messages Ä‘á»ƒ trÃ¡nh token limit
        if len(messages) > 10:
            messages = messages[-10:]
            
        return messages

    def _validate_response_language(self, response: str, expected_language: str) -> str:
        """Validate ngÃ´n ngá»¯ cá»§a response vÃ  sá»­a náº¿u cáº§n"""
        if not response:
            return response
        
        # PhÃ¡t hiá»‡n ngÃ´n ngá»¯
        vietnamese_chars = "Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Ãªá»áº¿á»‡á»ƒá»…Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘"
        has_vietnamese = any(char in response for char in vietnamese_chars)
        
        detected_language = "vi" if has_vietnamese else "en"
        
        if detected_language != expected_language:
            print(f"âš ï¸ WARNING: Language mismatch! Expected: {expected_language}, Got: {detected_language}")
            
            # ThÃªm warning dá»±a trÃªn ngÃ´n ngá»¯ mong muá»‘n
            warnings = {
                "vi": "[LÆ°u Ã½: ÄÃ¢y lÃ  báº£n dá»‹ch tá»± Ä‘á»™ng tá»« tiáº¿ng Anh]\n\n",
                "en": "[Note: This is an auto-translation from Vietnamese]\n\n"
            }
            
            warning = warnings.get(expected_language, "")
            response = warning + response
        
        return response

    # ================= RETRIEVER IMPLEMENTATION =================
    def _get_retriever(self):
        """Táº¡o retriever tá»« vector store"""
        class VectorStoreRetriever:
            def __init__(self, vector_store, k=3):
                self.vector_store = vector_store
                self.k = k
            
            def get_relevant_documents(self, query):
                results = self.vector_store.search_similar(query, k=self.k)
                documents = []
                for result in results:
                    # Táº¡o document object tÆ°Æ¡ng thÃ­ch vá»›i LangChain
                    class Document:
                        def __init__(self, page_content, metadata):
                            self.page_content = page_content
                            self.metadata = metadata
                    
                    doc = Document(
                        page_content=result['text'],
                        metadata=result['metadata']
                    )
                    # ThÃªm score náº¿u cÃ³
                    if 'score' in result:
                        doc.score = result['score']
                    documents.append(doc)
                return documents
        
        return VectorStoreRetriever(self.vector_store, k=5)

    # ================= HÃ€M Xá»¬ LÃ CÃ‚U Há»ŽI CHÃNH =================
    def get_response(self, question: str, session_id: str = "default",
                 language: str = None) -> Dict[str, Any]:  # Äá»•i máº·c Ä‘á»‹nh thÃ nh None
        """
        Xá»­ lÃ½ cÃ¢u há»i vá»›i pipeline hoÃ n chá»‰nh: NLU â†’ Retrieval â†’ Generation
        """
        print(f"ðŸ” Vector store info:")
        try:
            # Kiá»ƒm tra sá»‘ lÆ°á»£ng documents
            if hasattr(self.vector_store, 'get_collection_stats'):
                stats = self.vector_store.get_collection_stats()
                print(f"   Documents: {stats.get('total_documents', 'N/A')}")
            
            
            # Chuáº©n hÃ³a cÃ¢u há»i trÆ°á»›c khi tÃ¬m kiáº¿m
            normalized_query = remove_accents(question[:50].lower())

            retriever = self._get_retriever()
            test_docs = retriever.get_relevant_documents(normalized_query)
            print(f"   Retrieved {len(test_docs)} documents for query")
            
            for i, doc in enumerate(test_docs[:3]):  # Hiá»ƒn thá»‹ 3 docs Ä‘áº§u
                print(f"   Doc {i+1}: {doc.page_content[:100]}...")
                print(f"   Metadata: {doc.metadata}")
                
        except Exception as e:
            print(f"   Vector store debug error: {e}")
        try:
            # === BÆ¯á»šC 0: PHÃT HIá»†N NGÃ”N NGá»® ===
            final_language = self._resolve_language(question, language)
            print(f"ðŸŒ Final language for response: {final_language}")
            
            # === BÆ¯á»šC 1: PhÃ¢n tÃ­ch NLU vá»›i language Ä‘Ã£ detect ===
            nlu_result = self.nlu_processor.process_nlu(question, final_language, session_id)
            
            print(f"ðŸ” NLU Analysis: intent='{nlu_result['intent']}', language={final_language}")
            
            # KIá»‚M TRA: Náº¿u NLU cÃ³ lá»—i há»‡ thá»‘ng (QUOTA Háº¾T)
            if nlu_result.get("intent") == "system_error" and nlu_result.get("emergency_response"):
                print("âš ï¸ SYSTEM ERROR DETECTED IN NLU - Using emergency response")
                
                response = nlu_result["emergency_response"]
                
                self.memory_manager.save_context(
                    session_id, question, response, 
                    "system_error", 
                    nlu_result.get("entities", {})
                )
                
                return {
                    "answer": response,
                    "intent": "system_error",
                    "entities": nlu_result.get("entities", {}),
                    "sources": [],
                    "confidence": 0.0,
                    "has_context": False,
                    "language": final_language,
                    "system_error": True,
                    "error_type": nlu_result.get("error_type", "unknown")
                }
            
            # KIá»‚M TRA: Náº¿u NLU cÃ³ llm_error (quota nhÆ°ng chÆ°a Ä‘áº¿n system_error)
            if nlu_result.get("llm_error"):
                print("âš ï¸ LLM ERROR detected in NLU - Using fallback response")
                
                error_responses = {
                    "vi": "ChÃºng tÃ´i Ä‘ang gáº·p sá»± cá»‘ ká»¹ thuáº­t. Vui lÃ²ng liÃªn há»‡ support@arbin.com Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£.",
                    "en": "We're experiencing technical issues. Please contact support@arbin.com for assistance."
                }
                
                response = error_responses.get(final_language, error_responses["en"])
                
                self.memory_manager.save_context(
                    session_id, question, response, 
                    "system_error", 
                    nlu_result.get("entities", {})
                )
                
                return {
                    "answer": response,
                    "intent": "system_error",
                    "entities": nlu_result.get("entities", {}),
                    "sources": [],
                    "confidence": 0.0,
                    "has_context": False,
                    "language": final_language,
                    "system_error": True
                }
            
            intent = nlu_result["intent"]
            entities = nlu_result["entities"]
            enriched_text = nlu_result.get("enriched_text", question)
            
            print(f"ðŸ” NLU Analysis: intent='{intent}', language={final_language}, confidence={nlu_result['overall_confidence']:.2f}")
            if entities:
                print(f"   Entities: { {k: v for k, v in entities.items() if v} }")

            # BÆ°á»›c 2: Láº¥y dá»¯ liá»‡u há»™i thoáº¡i tá»« bá»™ nhá»›
            chat_history = self.memory_manager.get_chat_history(session_id)

            # BÆ°á»›c 3: Xá»­ lÃ½ Ä‘áº·c biá»‡t cho tá»«ng intent
            effective_query = self._enhance_query_for_retrieval(enriched_text, intent, entities)
            
            print(f"ðŸ“ Effective query for retrieval: '{effective_query}'")
            
            # BÆ°á»›c 4: Retrieve documents
            
            retriever = self._get_retriever()
            query_norm = remove_accents(effective_query.lower())
            docs = retriever.get_relevant_documents(query_norm)
            
            if not docs:
                # Fallback: Thá»­ vá»›i query gá»‘c
                docs = retriever.get_relevant_documents(question)
                
            if not docs:
                response = self._handle_no_documents(intent, question, final_language, chat_history)
                self.memory_manager.save_context(session_id, question, response, intent, entities)
                return {
                    "answer": response,
                    "intent": intent,
                    "entities": entities,
                    "sources": [],
                    "confidence": nlu_result["overall_confidence"],
                    "has_context": False,
                    "language": final_language  # ThÃªm language vÃ o response
                }

            # BÆ°á»›c 5: Format context tá»« documents
            context = self._format_context(docs, intent, entities)
            
            # BÆ°á»›c 6: Chá»n prompt vÃ  generate response
            response = self._generate_response(
                question=question,
                context=context,
                intent=intent,
                language=final_language,  # DÃ¹ng final_language
                chat_history=chat_history,
                entities=entities
            )
            
            # BÆ°á»›c 7: Format sources
            sources = self._format_sources(docs)
            
            # BÆ°á»›c 8: LÆ°u vÃ o memory
            self.memory_manager.save_context(session_id, question, response, intent, entities)
            
            return {
                "answer": response,
                "intent": intent,
                "entities": entities,
                "sources": sources,
                "confidence": nlu_result["overall_confidence"],
                "has_context": True,
                "language": final_language,  # ThÃªm language vÃ o response
                "context_preview": context[:500] + "..." if len(context) > 500 else context
            }

        except Exception as e:
            print(f"âŒ Lá»—i nghiÃªm trá»ng trong get_response: {e}")
            import traceback
            traceback.print_exc()
            
            # Emergency response cá»©ng
            lang = final_language if final_language in ["vi", "en"] else "en"
            emergency = {
                "vi": "ChÃºng tÃ´i Ä‘ang gáº·p sá»± cá»‘ ká»¹ thuáº­t. Vui lÃ²ng liÃªn há»‡ support@arbin.com Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£.",
                "en": "We're experiencing technical issues. Please contact support@arbin.com for assistance."
            }
            
            self.memory_manager.save_context(session_id, question, emergency.get(lang, emergency["en"]), "error", {})
            
            return {
                "answer": emergency.get(lang, emergency["en"]),
                "intent": "error",
                "entities": {},
                "sources": [],
                "confidence": 0.0,
                "has_context": False,
                "language": lang,
                "system_error": True
            }

    # ================= HÃ€M Há»– TRá»¢ (giá»¯ nguyÃªn tá»« báº£n gá»‘c, chá»‰ sá»­a lá»—i nhá») =================
    
    def _enhance_query_for_retrieval(self, query: str, intent: str, entities: Dict) -> str:
        """Enhance query Ä‘á»ƒ cáº£i thiá»‡n retrieval"""
        if not query:
            query = ""
        
        enhanced_parts = [query]
        
        # ThÃªm product names
        if entities and entities.get("product_names"):
            for product in entities["product_names"][:2]:
                if product:
                    enhanced_parts.append(str(product))
        
        # ThÃªm tá»« khÃ³a dá»±a trÃªn intent
        intent_keywords = {
            "product_inquiry": ["product", "model", "specifications"],
            "technical_support": ["error", "problem", "troubleshoot"],
            "specification_request": ["specification", "parameter", "technical"],
            "comparison_request": ["compare", "difference", "versus"],
            "application_info": ["application", "use", "purpose"],
            "pricing_inquiry": ["price", "cost", "quote"]
        }
        
        if intent in intent_keywords:
            enhanced_parts.extend(intent_keywords[intent])
        
        # Lá»c vÃ  join
        filtered_parts = []
        for part in enhanced_parts:
            if part and str(part).strip():
                filtered_parts.append(str(part).strip())
        
        if not filtered_parts:
            return "general inquiry"
        
        # Remove duplicates
        unique_parts = []
        seen = set()
        for part in filtered_parts:
            if part not in seen:
                seen.add(part)
                unique_parts.append(part)
        
        return " ".join(unique_parts)

    def _format_context(self, docs, intent: str, entities: Dict) -> str:
        """Format documents thÃ nh context string phÃ¹ há»£p vá»›i intent"""
        if not docs:
            return ""
        
        context_parts = []
        
        # Header dá»±a trÃªn intent
        intent_headers = {
            "product_inquiry": "THÃ”NG TIN Sáº¢N PHáº¨M ARBIN:",
            "technical_support": "TÃ€I LIá»†U Ká»¸ THUáº¬T ARBIN:",
            "specification_request": "THÃ”NG Sá» Ká»¸ THUáº¬T ARBIN:",
            "comparison_request": "THÃ”NG TIN SO SÃNH Sáº¢N PHáº¨M:",
            "application_info": "THÃ”NG TIN á»¨NG Dá»¤NG ARBIN:",
            "general_info": "THÃ”NG TIN ARBIN:"
        }
        
        header = intent_headers.get(intent, "THÃ”NG TIN THAM KHáº¢O:")
        context_parts.append(header)
        context_parts.append("")
        
        # Lá»c vÃ  format documents
        for i, doc in enumerate(docs[:3]):  # Giá»›i háº¡n 3 documents
            # Extract metadata
            metadata = getattr(doc, 'metadata', {})
            title = metadata.get('title', f"Document {i+1}")
            source = metadata.get('source', 'Unknown')
            
            # Format content (giá»›i háº¡n Ä‘á»™ dÃ i)
            content = doc.page_content
            if len(content) > 800:
                content = content[:800] + "..."
            
            # ThÃªm vÃ o context
            context_parts.append(f"[{i+1}] {title} ({source})")
            context_parts.append(content)
            context_parts.append("---")
        
        return "\n".join(context_parts)

    

    def _post_process_response(self, response: str, intent: str, entities: Dict) -> str:
        """LÃ m cÃ¢u tráº£ lá»i thÃ¢n thiá»‡n - FIX NHANH"""
        if not isinstance(response, str):
            response = str(response)
        
        # 1. PhÃ¡t hiá»‡n greeting trong response
        response_lower = response.lower()
        greeting_words = ["xin chÃ o", "hello", "hi", "chÃ o", "hey", "greetings"]
        
        is_greeting_response = any(
            word in response_lower and response_lower.count(word) >= 2 
            for word in greeting_words
        )
        
        # Náº¿u lÃ  greeting response, khÃ´ng thÃªm gÃ¬ cáº£
        if is_greeting_response:
            # Chá»‰ giá»¯ láº¡i 1 lá»i chÃ o
            for word in greeting_words:
                if word in response_lower:
                    # Äáº¿m sá»‘ láº§n xuáº¥t hiá»‡n
                    count = response_lower.count(word)
                    if count > 1:
                        # Thay tháº¿ táº¥t cáº£ trá»« láº§n Ä‘áº§u tiÃªn
                        parts = response.split(word)
                        if len(parts) > 2:
                            response = parts[0] + word + ''.join(parts[2:])
                    break
            
            return response.strip()
        
        # 2. PhÃ¡t hiá»‡n ngÃ´n ngá»¯
        vietnamese_chars = "Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Ãªá»áº¿á»‡á»ƒá»…"
        lang = "vi" if any(char in response for char in vietnamese_chars) else "en"
        
        # 3. KIá»‚M TRA: Náº¿u response Ä‘Ã£ báº¯t Ä‘áº§u báº±ng lá»i chÃ o/cáº£m Æ¡n, khÃ´ng thÃªm ná»¯a
        starts_with_greeting = response_lower.startswith(
            ("cáº£m Æ¡n", "thanks", "thank you", "xin chÃ o", "hello", "hi", "hey")
        )
        
        if not starts_with_greeting:
            # ThÃªm prefix Ä‘Æ¡n giáº£n
            simple_prefixes = {
                "vi": ["", ""],  # KhÃ´ng thÃªm prefix
                "en": ["", ""]
            }
            prefix = simple_prefixes.get(lang, [""])[0]
            response = prefix + response
        
        # 4. ThÃªm emoji Ä‘Æ¡n giáº£n
        if lang == "vi":
            emoji = "ðŸ’¡ "
            response = emoji + response
        
        # 5. Clean up
        response = re.sub(r'\n{3,}', '\n\n', response)
        return response.strip()

    def _format_sources(self, docs) -> List[Dict[str, str]]:
        """Format sources cho hiá»ƒn thá»‹"""
        sources = []
        
        for i, doc in enumerate(docs[:3]):  # Chá»‰ láº¥y top 3 sources
            metadata = getattr(doc, 'metadata', {})
            
            source = {
                'index': i + 1,
                'title': metadata.get('title', f"Document {i+1}"),
                'source_type': metadata.get('source', 'Unknown'),
                'url': metadata.get('url', ''),
                'file_name': metadata.get('file_name', ''),
                'relevance_score': getattr(doc, 'score', 0) if hasattr(doc, 'score') else 0,
                'content_preview': doc.page_content[:150] + '...' if len(doc.page_content) > 150 else doc.page_content
            }
            sources.append(source)
        
        return sources

    def _handle_no_documents(self, intent: str, question: str, language: str, chat_history: str) -> str:
        """
        Gá»i KnowledgeBase khi khÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u trong vector store.
        PhiÃªn báº£n nÃ¢ng cao: tráº£ lá»i tá»± nhiÃªn, dá»±a trÃªn lá»‹ch sá»­ há»™i thoáº¡i,
        thÃªm follow-up question giá»‘ng ChatGPT.
        """
        from ai_core.knowledge_base import KnowledgeBase
        import os

        # 1ï¸âƒ£ XÃ¡c Ä‘á»‹nh ngÃ´n ngá»¯
        lang = language if language in ["vi", "en"] else "en"

        # 2ï¸âƒ£ Prefix thÃ¢n thiá»‡n, dáº¡ng má»Ÿ Ä‘áº§u há»™i thoáº¡i
        friendly_intro = {
            "vi": "Cáº£m Æ¡n báº¡n Ä‘Ã£ há»i! ",
            "en": "Thanks for asking! "
        }[lang]

        # 3ï¸âƒ£ Load KnowledgeBase
        kb_path = os.path.join(os.path.dirname(__file__), "knowledge_base", "knowledge_base.json")
        kb_response = None

        if os.path.exists(kb_path):
            try:
                kb = KnowledgeBase(kb_path)
                kb_response = kb.find_answer(question, lang)
            except Exception as e:
                print(f"âš ï¸ KnowledgeBase load error: {e}")

        # 4ï¸âƒ£ Náº¿u KB khÃ´ng tráº£ lá»i Ä‘Æ°á»£c, táº¡o fallback message tá»± nhiÃªn, dá»±a trÃªn intent
        if not kb_response:
            if lang == "vi":
                kb_response = (
                    "MÃ¬nh chÆ°a tÃ¬m tháº¥y thÃ´ng tin cá»¥ thá»ƒ cho cÃ¢u há»i nÃ y. "
                    "Báº¡n cÃ³ thá»ƒ truy cáº­p www.arbin.com hoáº·c gá»­i email Ä‘áº¿n support@arbin.com Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t. "
                    "Náº¿u muá»‘n, mÃ¬nh cÃ³ thá»ƒ gá»£i Ã½ má»™t sá»‘ cÃ¡ch kiá»ƒm tra hoáº·c tÃ¬m thÃ´ng tin khÃ¡c cho báº¡n. "
                )
            else:
                kb_response = (
                    "I couldnâ€™t find specific information for this question. "
                    "You may check www.arbin.com or email support@arbin.com for more details. "
                    "If you like, I can suggest ways to find more info or troubleshoot."
                )

        # 5ï¸âƒ£ ThÃªm follow-up dá»±a trÃªn lá»‹ch sá»­ há»™i thoáº¡i
        if chat_history:
            follow_up = {
                "vi": "Báº¡n cÃ³ muá»‘n mÃ¬nh giáº£i thÃ­ch thÃªm hoáº·c cung cáº¥p hÆ°á»›ng dáº«n chi tiáº¿t khÃ´ng?",
                "en": "Would you like me to explain further or provide step-by-step guidance?"
            }[lang]
            kb_response = f"{kb_response} {follow_up}"

        # 6ï¸âƒ£ Giá»›i háº¡n Ä‘á»™ dÃ i cÃ¢u tráº£ lá»i
        max_len = 600
        if len(kb_response) > max_len:
            kb_response = kb_response[:max_len] + "..."

        # 7ï¸âƒ£ Gá»™p prefix vÃ  ná»™i dung tráº£ lá»i
        full_response = f"{friendly_intro}{kb_response}"

        # 8ï¸âƒ£ Log chi tiáº¿t
        print(f"ðŸ“˜ [KB/Fallback] Intent={intent} | Lang={lang} | Question={question[:50]} | Answer={kb_response[:80]}...")

        return full_response


    # ================= BATCH PROCESSING =================
    def batch_get_response(self, questions: List[str], session_id: str = "default",
                          language: str = "en") -> List[Dict[str, Any]]:
        """Xá»­ lÃ½ hÃ ng loáº¡t cÃ¢u há»i"""
        results = []
        for question in questions:
            try:
                result = self.get_response(question, session_id, language)
                results.append(result)
            except Exception as e:
                print(f"âŒ Lá»—i xá»­ lÃ½ cÃ¢u há»i '{question}': {e}")
                results.append({
                    "answer": "Error processing question",
                    "intent": "error",
                    "entities": {},
                    "sources": [],
                    "confidence": 0.0,
                    "has_context": False
                })
        
        return results

    # ================= SYSTEM STATUS =================
    def get_system_status(self) -> Dict[str, Any]:
        """Láº¥y tráº¡ng thÃ¡i há»‡ thá»‘ng"""
        try:
            # Kiá»ƒm tra vector store
            store_status = "Unknown"
            try:
                stats = self.vector_store.get_collection_stats()
                count = stats.get('total_documents', 0)
                store_status = f"Operational ({count} documents)"
            except Exception as e:
                store_status = f"Not accessible: {str(e)}"
            
            # Kiá»ƒm tra memory
            memory_status = "Operational" if self.memory_manager else "Not initialized"
            
            # Kiá»ƒm tra LLM
            llm_status = "Operational" if self.llm else "Not initialized"
            
            return {
                'status': 'operational',
                'components': {
                    'vector_store': store_status,
                    'memory_manager': memory_status,
                    'llm': llm_status,
                    'nlu_processor': 'Operational'
                },
                'configuration': {
                    'retrieval_k': 5,
                    'language_default': 'en',
                    'max_context_length': 4000
                }
            }
            
        except Exception as e:
            return {
                'status': f'error: {str(e)}',
                'components': {
                    'vector_store': 'Unknown',
                    'memory_manager': 'Unknown',
                    'llm': 'Unknown',
                    'nlu_processor': 'Unknown'
                }
            }


# Factory function
def create_arbin_retrieval_qa(llm, vector_store) -> ArbinRetrievalQA:
    """Factory function Ä‘á»ƒ táº¡o ArbinRetrievalQA"""
    return ArbinRetrievalQA(llm=llm, vector_store=vector_store)